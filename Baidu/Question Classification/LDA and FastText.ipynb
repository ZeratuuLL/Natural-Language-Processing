{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from itertools import permutations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/09/k_9rj22d0dgbjd8832nhvlbh0000gn/T/jieba.cache\n",
      "Loading model cost 0.586 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict('./stopwords/Special_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = {'history' : './data/百度题库/高中_历史/origin/', \n",
    "         'geology' : './data/百度题库/高中_地理/origin/',\n",
    "         'politics' : './data/百度题库/高中_政治/origin/',\n",
    "         'biology' : './data/百度题库/高中_生物/origin/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(root):\n",
    "    '''\n",
    "    This function reads in all csv files lies directly under the root directory\n",
    "    \n",
    "    Returns the file directories as well as class names (file names)\n",
    "    '''\n",
    "    file_names = os.listdir(root)\n",
    "    file_names = [name for name in file_names if name.endswith('csv')]\n",
    "    classes = [name.split('.')[0] for name in file_names]\n",
    "    file_names = [root + name for name in file_names]\n",
    "    datasets = [pd.read_csv(name) for name in file_names]\n",
    "    return datasets, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(path):\n",
    "    file = open(path, 'r', encoding='utf-8')\n",
    "    stopwords = file.readlines()\n",
    "    stopwords = [word.strip() for word in stopwords]\n",
    "    return stopwords\n",
    "\n",
    "stopwords = load_stop_words('./stopwords/stopwords2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = \"[a-zA-Z0-9]|[\\s+\\-\\|\\!\\/\\[\\]\\{\\}_,.$%^*(+\\\"\\')]+|[:：+——()?【】《》“”！，。？、~@#￥%……&*（）]+|题目|排除|选项|知识点\"\n",
    "def clean_sentence(line):\n",
    "    '''\n",
    "    This function cleans the context\n",
    "    '''\n",
    "    line = re.sub(remove, '', line)\n",
    "    tokens = jieba.cut(line, cut_all=False)\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    part1, part2 = line.split('题型', 1) # part 1 is 题目\n",
    "    part2, part3 = part2.split('解析', 1) # part 2 is abanddoned\n",
    "    part3 = part3.split('解析')[1]\n",
    "    try:\n",
    "        part3, part4 = part3.split('知识点', 1) # part 3 is 解析, part 4 is 知识点\n",
    "    except ValueError:\n",
    "        part4 = ''\n",
    "    result = []\n",
    "    for line in [part1, part3, part4]:\n",
    "        result.append(clean_sentence(line))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(root):\n",
    "    \n",
    "    datasets, classes = read_files(root)\n",
    "    \n",
    "    for dataset, label in zip(datasets, classes):\n",
    "        dataset['item'] = dataset['item'].apply(lambda x : clean_line(x))\n",
    "        dataset['question'] = dataset['item'].apply(lambda x : x[0]).apply(lambda x : x.split())\n",
    "        dataset['solution'] = dataset['item'].apply(lambda x : x[1]).apply(lambda x : x.split())\n",
    "        dataset['keypoints'] = dataset['item'].apply(lambda x : x[2]).apply(lambda x : x.split())\n",
    "        dataset['item'] = dataset['item'].apply(lambda x : ' '.join(x)).apply(lambda x : x.split())\n",
    "        dataset['label'] = label\n",
    "    \n",
    "    dataset = pd.concat(datasets, ignore_index = True)\n",
    "    dataset = dataset[['item', 'question', 'solution', 'keypoints', 'label']]\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "\n",
    "The topics in LDA are numbers but the label are strings. The correspondence might change among different runs. After different runs I realized that the results are not stable at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LDA(root):\n",
    "    \n",
    "    dataset = build_dataset(root)\n",
    "    num_topics = len(dataset['label'].unique())\n",
    "    common_texts=dataset['item'].tolist()\n",
    "    \n",
    "    dictionary = Dictionary(common_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in common_texts]\n",
    "    lda = LdaModel(corpus, id2word=dictionary, num_topics=num_topics)\n",
    "    \n",
    "    predictions = [lda.get_document_topics(text) for text in corpus]\n",
    "    \n",
    "    dataset['prediction'] = predictions\n",
    "    \n",
    "    labels = dataset['label'].unique()\n",
    "    pred = list(range(num_topics))\n",
    "    predictions = dataset['prediction'].apply(lambda x : sorted(x, key = lambda x : x[1], reverse=True)[0][0])\n",
    "    \n",
    "    best_match = 0\n",
    "    for match in permutations(pred):\n",
    "        num_to_pred = dict(zip(match, labels))\n",
    "        temp_prediction = predictions.apply(lambda x : num_to_pred[x])\n",
    "        correct = sum(temp_prediction.values == dataset['label'].values)\n",
    "        if correct > best_match:\n",
    "            best_match = correct\n",
    "            final_prediction = temp_prediction.values.copy()\n",
    "    \n",
    "    print(classification_report(dataset['label'].values, final_prediction))\n",
    "    \n",
    "    return dataset[['item', 'label', 'prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         古代史       0.51      0.91      0.65      1000\n",
      "         现代史       0.54      0.43      0.48      2330\n",
      "         近代史       0.41      0.33      0.36      1640\n",
      "\n",
      "    accuracy                           0.50      4970\n",
      "   macro avg       0.49      0.56      0.50      4970\n",
      "weighted avg       0.49      0.50      0.48      4970\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[左传, 记载, 春秋, 后期, 鲁国, 大夫, 季孙氏, 家臣, 阳虎, 独掌, 权柄, ...</td>\n",
       "      <td>古代史</td>\n",
       "      <td>[(0, 0.99040365)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[秦始皇, 统一, 六国后, 创制, 一套, 御玺, 任命, 国家, 官员, 封印, 皇帝,...</td>\n",
       "      <td>古代史</td>\n",
       "      <td>[(0, 0.9924977)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[北宋, 加强, 中央集权, 主要, 措施, 主要, 将领, 兵权, 收归, 中央, 派, ...</td>\n",
       "      <td>古代史</td>\n",
       "      <td>[(0, 0.9890275)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[商朝人, 崇信, 鬼神, 占卜, 祭祀, 神灵, 沟通, 手段, 负责, 通神, 事务, ...</td>\n",
       "      <td>古代史</td>\n",
       "      <td>[(0, 0.72350544), (2, 0.27250484)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[公元, 年, 北宋, 政府, 江淮地区, 设置, 包括, 盐业, 管理, 控制, 茶叶, ...</td>\n",
       "      <td>古代史</td>\n",
       "      <td>[(0, 0.7180145), (2, 0.27803382)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                item label  \\\n",
       "0  [左传, 记载, 春秋, 后期, 鲁国, 大夫, 季孙氏, 家臣, 阳虎, 独掌, 权柄, ...   古代史   \n",
       "1  [秦始皇, 统一, 六国后, 创制, 一套, 御玺, 任命, 国家, 官员, 封印, 皇帝,...   古代史   \n",
       "2  [北宋, 加强, 中央集权, 主要, 措施, 主要, 将领, 兵权, 收归, 中央, 派, ...   古代史   \n",
       "3  [商朝人, 崇信, 鬼神, 占卜, 祭祀, 神灵, 沟通, 手段, 负责, 通神, 事务, ...   古代史   \n",
       "4  [公元, 年, 北宋, 政府, 江淮地区, 设置, 包括, 盐业, 管理, 控制, 茶叶, ...   古代史   \n",
       "\n",
       "                           prediction  \n",
       "0                   [(0, 0.99040365)]  \n",
       "1                    [(0, 0.9924977)]  \n",
       "2                    [(0, 0.9890275)]  \n",
       "3  [(0, 0.72350544), (2, 0.27250484)]  \n",
       "4   [(0, 0.7180145), (2, 0.27803382)]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = train_LDA(roots['history'])\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       人口与城市       0.49      0.85      0.62      1570\n",
      "     区域可持续发展       0.00      0.02      0.00       130\n",
      "       地球与地图       0.11      0.29      0.15       431\n",
      "      宇宙中的地球       0.88      0.44      0.59      3716\n",
      "   生产活动与地域联系       0.05      0.03      0.04      1340\n",
      "\n",
      "    accuracy                           0.44      7187\n",
      "   macro avg       0.31      0.32      0.28      7187\n",
      "weighted avg       0.58      0.44      0.46      7187\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[太阳系, 中, 地球, 行星, 重要, 区别, 存在, 生命, 物质, 质量, 最小, 平...</td>\n",
       "      <td>宇宙中的地球</td>\n",
       "      <td>[(0, 0.74310714), (1, 0.24203418)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[时区, 叙述, 不, 全球, 共, 分成, 时区, 北京, 时间, 不是, 北京, 地方,...</td>\n",
       "      <td>宇宙中的地球</td>\n",
       "      <td>[(2, 0.9884135)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[太阳活动, 叙述, 黑子, 实际上, 不, 黑, 温度, 太阳, 表面, 地方, 高, 耀...</td>\n",
       "      <td>宇宙中的地球</td>\n",
       "      <td>[(1, 0.9887558)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[各图, 中, 阴影, 部分, 代表, 黑夜, 代表, 晨线, 晨昏, 线, 定义, 地球,...</td>\n",
       "      <td>宇宙中的地球</td>\n",
       "      <td>[(4, 0.98192185)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[年, 地球, 将会, 遭遇, 强烈, 超级, 太阳风暴, 破坏力, 远远, 超过, 卡特里...</td>\n",
       "      <td>宇宙中的地球</td>\n",
       "      <td>[(0, 0.0813264), (1, 0.7201778), (4, 0.1939864)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                item   label  \\\n",
       "0  [太阳系, 中, 地球, 行星, 重要, 区别, 存在, 生命, 物质, 质量, 最小, 平...  宇宙中的地球   \n",
       "1  [时区, 叙述, 不, 全球, 共, 分成, 时区, 北京, 时间, 不是, 北京, 地方,...  宇宙中的地球   \n",
       "2  [太阳活动, 叙述, 黑子, 实际上, 不, 黑, 温度, 太阳, 表面, 地方, 高, 耀...  宇宙中的地球   \n",
       "3  [各图, 中, 阴影, 部分, 代表, 黑夜, 代表, 晨线, 晨昏, 线, 定义, 地球,...  宇宙中的地球   \n",
       "4  [年, 地球, 将会, 遭遇, 强烈, 超级, 太阳风暴, 破坏力, 远远, 超过, 卡特里...  宇宙中的地球   \n",
       "\n",
       "                                         prediction  \n",
       "0                [(0, 0.74310714), (1, 0.24203418)]  \n",
       "1                                  [(2, 0.9884135)]  \n",
       "2                                  [(1, 0.9887558)]  \n",
       "3                                 [(4, 0.98192185)]  \n",
       "4  [(0, 0.0813264), (1, 0.7201778), (4, 0.1939864)]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geology = train_LDA(roots['geology'])\n",
    "geology.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   公民道德与伦理常识       0.68      0.29      0.40      1760\n",
      "        时事政治       0.07      0.52      0.13        67\n",
      "    生活中的法律常识       0.21      0.35      0.26       170\n",
      "      科学思维常识       0.25      0.51      0.33       260\n",
      "    科学社会主义常识       0.53      0.51      0.52       573\n",
      "       经济学常识       0.29      0.41      0.34       566\n",
      "\n",
      "    accuracy                           0.37      3396\n",
      "   macro avg       0.34      0.43      0.33      3396\n",
      "weighted avg       0.52      0.37      0.39      3396\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[年, 政府, 工作, 报告, 提出, 缩小, 收入, 分配, 差距, 使, 发展, 成果,...</td>\n",
       "      <td>公民道德与伦理常识</td>\n",
       "      <td>[(1, 0.98935336)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[做, 蛋糕, 分, 蛋糕, 经济社会, 面临, 最, 基本, 问题, 既要, 蛋糕, 做,...</td>\n",
       "      <td>公民道德与伦理常识</td>\n",
       "      <td>[(5, 0.9843866)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[最近, 常有, 手机用户, 收到, 老朋友, 名义, 发来, 短信, 短信, 极易, 引诱...</td>\n",
       "      <td>公民道德与伦理常识</td>\n",
       "      <td>[(2, 0.9902019)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[家庭, 人生, 第一, 课堂, 父母, 子女, 第一任, 教师, 家庭教育, 子女, 健康...</td>\n",
       "      <td>公民道德与伦理常识</td>\n",
       "      <td>[(0, 0.9766222)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[社会主义, 市场经济, 指, 市场, 国家, 下, 资源配置, 作用, 经济, 社会主义,...</td>\n",
       "      <td>公民道德与伦理常识</td>\n",
       "      <td>[(4, 0.97597456)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                item      label  \\\n",
       "0  [年, 政府, 工作, 报告, 提出, 缩小, 收入, 分配, 差距, 使, 发展, 成果,...  公民道德与伦理常识   \n",
       "1  [做, 蛋糕, 分, 蛋糕, 经济社会, 面临, 最, 基本, 问题, 既要, 蛋糕, 做,...  公民道德与伦理常识   \n",
       "2  [最近, 常有, 手机用户, 收到, 老朋友, 名义, 发来, 短信, 短信, 极易, 引诱...  公民道德与伦理常识   \n",
       "3  [家庭, 人生, 第一, 课堂, 父母, 子女, 第一任, 教师, 家庭教育, 子女, 健康...  公民道德与伦理常识   \n",
       "4  [社会主义, 市场经济, 指, 市场, 国家, 下, 资源配置, 作用, 经济, 社会主义,...  公民道德与伦理常识   \n",
       "\n",
       "          prediction  \n",
       "0  [(1, 0.98935336)]  \n",
       "1   [(5, 0.9843866)]  \n",
       "2   [(2, 0.9902019)]  \n",
       "3   [(0, 0.9766222)]  \n",
       "4  [(4, 0.97597456)]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics = train_LDA(roots['politics'])\n",
    "politics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       分子与细胞       0.57      0.37      0.45      2980\n",
      "    现代生物技术专题       0.31      0.58      0.41      1000\n",
      "      生物技术实践       0.17      0.14      0.15      1770\n",
      "     生物科学与社会       0.74      0.85      0.79      3900\n",
      "       稳态与环境       0.70      0.56      0.62      3570\n",
      "       遗传与进化       0.01      0.02      0.01      1040\n",
      "\n",
      "    accuracy                           0.51     14260\n",
      "   macro avg       0.42      0.42      0.41     14260\n",
      "weighted avg       0.54      0.51      0.52     14260\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[细胞, 内, 含量, 最多, 有机, 化合物, 化合物, 分别, 蛋白质, 水, 蛋白质,...</td>\n",
       "      <td>分子与细胞</td>\n",
       "      <td>[(0, 0.21096516), (1, 0.33608967), (4, 0.44554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[下图, 生物膜, 流动, 镶嵌, 模型, 物质, 跨膜, 运输, 示意图, 离子通道, 一...</td>\n",
       "      <td>分子与细胞</td>\n",
       "      <td>[(0, 0.087426126), (3, 0.2820882), (4, 0.62777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[多肽, 有个, 氨基酸, 天冬氨酸, 分别, 位于, 第位, 如图所示, 肽酶, 专门, ...</td>\n",
       "      <td>分子与细胞</td>\n",
       "      <td>[(0, 0.19144966), (2, 0.79875475)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[具有, 细胞, 结构, 没有, 核膜, 一组, 生物, 病毒, 乳酸菌, 细菌, 念珠, ...</td>\n",
       "      <td>分子与细胞</td>\n",
       "      <td>[(3, 0.958468), (4, 0.035375662)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[实验, 中, 同一, 显微镜, 观察, 同一, 装片次, 得到, 清晰, 四个, 物像, ...</td>\n",
       "      <td>分子与细胞</td>\n",
       "      <td>[(3, 0.9949663)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                item  label  \\\n",
       "0  [细胞, 内, 含量, 最多, 有机, 化合物, 化合物, 分别, 蛋白质, 水, 蛋白质,...  分子与细胞   \n",
       "1  [下图, 生物膜, 流动, 镶嵌, 模型, 物质, 跨膜, 运输, 示意图, 离子通道, 一...  分子与细胞   \n",
       "2  [多肽, 有个, 氨基酸, 天冬氨酸, 分别, 位于, 第位, 如图所示, 肽酶, 专门, ...  分子与细胞   \n",
       "3  [具有, 细胞, 结构, 没有, 核膜, 一组, 生物, 病毒, 乳酸菌, 细菌, 念珠, ...  分子与细胞   \n",
       "4  [实验, 中, 同一, 显微镜, 观察, 同一, 装片次, 得到, 清晰, 四个, 物像, ...  分子与细胞   \n",
       "\n",
       "                                          prediction  \n",
       "0  [(0, 0.21096516), (1, 0.33608967), (4, 0.44554...  \n",
       "1  [(0, 0.087426126), (3, 0.2820882), (4, 0.62777...  \n",
       "2                 [(0, 0.19144966), (2, 0.79875475)]  \n",
       "3                  [(3, 0.958468), (4, 0.035375662)]  \n",
       "4                                   [(3, 0.9949663)]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biology = train_LDA(roots['biology'])\n",
    "biology.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, word_size, class_num, pad_token):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.embedding = nn.Embedding(word_size, embedding_size, pad_token)\n",
    "        self.fc1 = nn.Linear(embedding_size, class_num)\n",
    "        self.output = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, sentences):\n",
    "        \n",
    "        embedded = self.embedding(sentences)\n",
    "        with torch.no_grad():\n",
    "            # number of effective words (remove <PAD>)\n",
    "            word_count = (embedded.pow(2).sum(dim=-1)>0).sum(dim=-1).view(-1, 1).float()\n",
    "        embedded = embedded.sum(dim = 1) / word_count\n",
    "        logits = self.output(self.fc1(embedded))\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_proc(sentence, max_len, word2id):\n",
    "    \n",
    "    if len(sentence) > max_len:\n",
    "        sentence = sentence[:max_len]\n",
    "    else:\n",
    "        sentence += ['<PAD>'] * (max_len - len(sentence))\n",
    "        \n",
    "    sentence = [word2id.get(word, word2id['<OOV>']) for word in sentence]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pad_words(texts, max_feature):\n",
    "    \n",
    "    word_list = [word for sentence in texts for word in sentence]\n",
    "    counter = Counter(word_list)\n",
    "    counter = [(word, count) for word, count in counter.items()]\n",
    "    counter.sort(key = lambda x : x[1], reverse = True)\n",
    "    \n",
    "    valid_words = [word for word, _ in counter[:max_feature]]\n",
    "    word2id = dict(zip(valid_words, range(1, len(valid_words) + 1) ) )\n",
    "    word2id['<OOV>'] = 0\n",
    "    word2id['<PAD>'] = len(word2id)\n",
    "    \n",
    "    lens = [len(sentence) for sentence in texts]\n",
    "    max_len = int(np.mean(lens) + 2 * np.std(lens))\n",
    "    \n",
    "    texts = [sentence_proc(sentence, max_len, word2id) for sentence in texts]\n",
    "    \n",
    "    return texts, word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_FastText(subject, NGramRange=1, max_feature=10000, embedding_size = 300, epoch = 20):\n",
    "    \n",
    "    print('Reading Data')\n",
    "    root = roots[subject]\n",
    "    dataset = build_dataset(root)\n",
    "    num_topics = len(dataset['label'].unique())\n",
    "    dataset['item'] = dataset['item']\n",
    "    common_texts=dataset['item'].tolist()\n",
    "    \n",
    "    print('Cleaning Data')\n",
    "    common_texts, word2id = filter_pad_words(common_texts, max_feature)\n",
    "    \n",
    "    FastText = Network(embedding_size, len(word2id), num_topics, len(word2id)-1).to(device)\n",
    "    optimizer = optim.Adam(FastText.parameters(), 0.001)\n",
    "    \n",
    "    print('Creating training/testing set')\n",
    "    label2id = dict(zip(dataset['label'].unique(), range(num_topics)))\n",
    "    id2label = dict(zip(label2id.values(), label2id.keys()))\n",
    "    X = np.array(common_texts)\n",
    "    y = np.array([label2id[label] for label in dataset['label']]).reshape(-1, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 101)\n",
    "    \n",
    "    X_train = torch.tensor(X_train).long()\n",
    "    y_train = torch.tensor(y_train).long()\n",
    "    X_test = torch.tensor(X_test).long()\n",
    "    y_test = torch.tensor(y_test).long()\n",
    "    train = TensorDataset(X_train, y_train)\n",
    "    test = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train, 64, True)\n",
    "    test_loader = DataLoader(test, 64, False)\n",
    "    \n",
    "    print('Training\\n')\n",
    "    criterion = nn.NLLLoss()\n",
    "    for i in range(1, epoch + 1):\n",
    "        \n",
    "        log = []\n",
    "        \n",
    "        for X_sample, y_sample in iter(train_loader):\n",
    "            \n",
    "            X_sample = X_sample.to(device)\n",
    "            y_sample = y_sample.view(-1).to(device)\n",
    "            logits = FastText(X_sample)\n",
    "            loss = criterion(logits, y_sample)\n",
    "            log.append(loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print('Epoch {}. Average loss {:.4f}'.format(i, np.mean(log)))\n",
    "        \n",
    "    print('\\nTesting\\n')\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X_sample, _ in iter(test_loader):\n",
    "            \n",
    "            X_sample = X_sample.to(device)\n",
    "            logits = FastText(X_sample)\n",
    "            _, index = logits.topk(1, 1)\n",
    "            index = index.view(-1).numpy().tolist()\n",
    "            predictions += index\n",
    "    \n",
    "    y_test = y_test.reshape(-1).tolist()\n",
    "    y_test = [id2label[ind] for ind in y_test]\n",
    "    predictions = [id2label[ind] for ind in predictions]\n",
    "    \n",
    "    print('\\nTest result for {} :'.format(subject))\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    return FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Cleaning Data\n",
      "Creating training/testing set\n",
      "Training\n",
      "\n",
      "Epoch 1. Average loss 0.9701\n",
      "Epoch 2. Average loss 0.7412\n",
      "Epoch 3. Average loss 0.5872\n",
      "Epoch 4. Average loss 0.4968\n",
      "Epoch 5. Average loss 0.4409\n",
      "Epoch 6. Average loss 0.4036\n",
      "Epoch 7. Average loss 0.3766\n",
      "Epoch 8. Average loss 0.3633\n",
      "Epoch 9. Average loss 0.3432\n",
      "Epoch 10. Average loss 0.3248\n",
      "Epoch 11. Average loss 0.3143\n",
      "Epoch 12. Average loss 0.3021\n",
      "Epoch 13. Average loss 0.2947\n",
      "Epoch 14. Average loss 0.2876\n",
      "Epoch 15. Average loss 0.2805\n",
      "Epoch 16. Average loss 0.2750\n",
      "Epoch 17. Average loss 0.2688\n",
      "Epoch 18. Average loss 0.2662\n",
      "Epoch 19. Average loss 0.2608\n",
      "Epoch 20. Average loss 0.2540\n",
      "\n",
      "Testing\n",
      "\n",
      "\n",
      "Test result for history :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         古代史       0.90      0.81      0.85       203\n",
      "         现代史       0.68      0.70      0.69       464\n",
      "         近代史       0.61      0.62      0.61       327\n",
      "\n",
      "    accuracy                           0.70       994\n",
      "   macro avg       0.73      0.71      0.72       994\n",
      "weighted avg       0.70      0.70      0.70       994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = train_FastText('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Cleaning Data\n",
      "Creating training/testing set\n",
      "Training\n",
      "\n",
      "Epoch 1. Average loss 0.9883\n",
      "Epoch 2. Average loss 0.4322\n",
      "Epoch 3. Average loss 0.2613\n",
      "Epoch 4. Average loss 0.1841\n",
      "Epoch 5. Average loss 0.1413\n",
      "Epoch 6. Average loss 0.1135\n",
      "Epoch 7. Average loss 0.0938\n",
      "Epoch 8. Average loss 0.0791\n",
      "Epoch 9. Average loss 0.0678\n",
      "Epoch 10. Average loss 0.0588\n",
      "Epoch 11. Average loss 0.0515\n",
      "Epoch 12. Average loss 0.0455\n",
      "Epoch 13. Average loss 0.0407\n",
      "Epoch 14. Average loss 0.0365\n",
      "Epoch 15. Average loss 0.0331\n",
      "Epoch 16. Average loss 0.0300\n",
      "Epoch 17. Average loss 0.0277\n",
      "Epoch 18. Average loss 0.0258\n",
      "Epoch 19. Average loss 0.0240\n",
      "Epoch 20. Average loss 0.0226\n",
      "\n",
      "Testing\n",
      "\n",
      "\n",
      "Test result for geology :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       人口与城市       0.94      0.94      0.94       308\n",
      "     区域可持续发展       0.89      0.65      0.76        26\n",
      "       地球与地图       0.91      0.81      0.86        93\n",
      "      宇宙中的地球       0.97      0.99      0.98       726\n",
      "   生产活动与地域联系       0.90      0.93      0.92       285\n",
      "\n",
      "    accuracy                           0.95      1438\n",
      "   macro avg       0.93      0.86      0.89      1438\n",
      "weighted avg       0.95      0.95      0.95      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = train_FastText('geology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Cleaning Data\n",
      "Creating training/testing set\n",
      "Training\n",
      "\n",
      "Epoch 1. Average loss 1.5284\n",
      "Epoch 2. Average loss 1.0353\n",
      "Epoch 3. Average loss 0.7145\n",
      "Epoch 4. Average loss 0.5094\n",
      "Epoch 5. Average loss 0.3839\n",
      "Epoch 6. Average loss 0.2990\n",
      "Epoch 7. Average loss 0.2366\n",
      "Epoch 8. Average loss 0.1927\n",
      "Epoch 9. Average loss 0.1587\n",
      "Epoch 10. Average loss 0.1322\n",
      "Epoch 11. Average loss 0.1114\n",
      "Epoch 12. Average loss 0.0948\n",
      "Epoch 13. Average loss 0.0805\n",
      "Epoch 14. Average loss 0.0695\n",
      "Epoch 15. Average loss 0.0603\n",
      "Epoch 16. Average loss 0.0525\n",
      "Epoch 17. Average loss 0.0459\n",
      "Epoch 18. Average loss 0.0399\n",
      "Epoch 19. Average loss 0.0353\n",
      "Epoch 20. Average loss 0.0313\n",
      "\n",
      "Testing\n",
      "\n",
      "\n",
      "Test result for politics :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   公民道德与伦理常识       0.95      0.98      0.96       357\n",
      "        时事政治       1.00      0.89      0.94         9\n",
      "    生活中的法律常识       1.00      0.81      0.90        37\n",
      "      科学思维常识       0.94      0.90      0.92        51\n",
      "    科学社会主义常识       0.93      0.97      0.95       103\n",
      "       经济学常识       0.98      0.91      0.95       123\n",
      "\n",
      "    accuracy                           0.95       680\n",
      "   macro avg       0.97      0.91      0.94       680\n",
      "weighted avg       0.95      0.95      0.95       680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = train_FastText('politics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Cleaning Data\n",
      "Creating training/testing set\n",
      "Training\n",
      "\n",
      "Epoch 1. Average loss 1.0818\n",
      "Epoch 2. Average loss 0.5393\n",
      "Epoch 3. Average loss 0.4493\n",
      "Epoch 4. Average loss 0.4130\n",
      "Epoch 5. Average loss 0.3893\n",
      "Epoch 6. Average loss 0.3726\n",
      "Epoch 7. Average loss 0.3609\n",
      "Epoch 8. Average loss 0.3479\n",
      "Epoch 9. Average loss 0.3395\n",
      "Epoch 10. Average loss 0.3296\n",
      "Epoch 11. Average loss 0.3208\n",
      "Epoch 12. Average loss 0.3142\n",
      "Epoch 13. Average loss 0.3072\n",
      "Epoch 14. Average loss 0.3022\n",
      "Epoch 15. Average loss 0.2969\n",
      "Epoch 16. Average loss 0.2920\n",
      "Epoch 17. Average loss 0.2867\n",
      "Epoch 18. Average loss 0.2832\n",
      "Epoch 19. Average loss 0.2794\n",
      "Epoch 20. Average loss 0.2761\n",
      "\n",
      "Testing\n",
      "\n",
      "\n",
      "Test result for biology :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       分子与细胞       0.90      0.90      0.90       584\n",
      "    现代生物技术专题       0.16      0.13      0.14       207\n",
      "      生物技术实践       0.45      0.49      0.47       332\n",
      "     生物科学与社会       0.72      0.77      0.75       796\n",
      "       稳态与环境       0.95      0.94      0.95       733\n",
      "       遗传与进化       0.40      0.33      0.36       200\n",
      "\n",
      "    accuracy                           0.73      2852\n",
      "   macro avg       0.60      0.59      0.59      2852\n",
      "weighted avg       0.72      0.73      0.73      2852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = train_FastText('biology')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
